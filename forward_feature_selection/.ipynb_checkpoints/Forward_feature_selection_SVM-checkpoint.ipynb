{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "root_path=current_path.replace('\\\\forward_feature_selection','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df=pd.read_csv(root_path+\"\\\\molecules.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_disk(df,name:str,separator=\"\\t\"):\n",
    "    df.to_csv(name,sep=separator,index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_true_prediction(df,not_wanted_features:list):\n",
    "        temp_df=df.drop(not_wanted_features,axis=1)\n",
    "        y=temp_df[temp_df.columns[-1]]\n",
    "        x=temp_df.drop([temp_df.columns[-1]],axis=1)\n",
    "        \n",
    "        return x,y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_name_and_prediction(df,true_prediction,big_df):\n",
    "    new_df=df\n",
    "    new_df.insert(0,\"m_name\",big_df[\"m_name\"].values)\n",
    "    new_df=new_df.join(true_prediction)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_auc_score(x,y,model): # gets roc auc average\n",
    "        cv_results = cross_validate(model, x, y, cv=10,scoring=('roc_auc'))\n",
    "        roc_auc_avrg=cv_results['test_score'].mean()\n",
    "        \n",
    "        return roc_auc_avrg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(x,y,model): # O(n) worst case scenario, where n depends on len(x.columns)\n",
    "    \n",
    "    def first_iteration(x,y,model):\n",
    "        score_lst=[]\n",
    "        for i in range(len(x.columns)):\n",
    "            k=x.columns[i]\n",
    "            temp_x=x[[k]]\n",
    "            score=get_roc_auc_score(temp_x,y,model)\n",
    "            score_lst.append(score)\n",
    "\n",
    "        max_score = max(score_lst) # best score\n",
    "        max_score_index=[i for i, j in enumerate(score_lst) if j == max_score] # indx with best score \n",
    "        new_features=[x.columns[i] for i in max_score_index]\n",
    "        top_new_features=new_features[0]\n",
    "        best_x=x[top_new_features]\n",
    "        new_x=x.drop(top_new_features,axis=1)\n",
    "        \n",
    "        return best_x,new_x,max_score\n",
    "    \n",
    "    def else_iteration(best_x,x,y,model,actual_score):     \n",
    "        new_x_lenght = len(x.columns)\n",
    "        if (new_x_lenght > 0):\n",
    "            score_lst=[]\n",
    "            for i in range(new_x_lenght):\n",
    "                k=x.columns[i]\n",
    "                temp_x=x[[k]]\n",
    "                temp_new_x=pd.concat([best_x,temp_x],axis=1, ignore_index=True)\n",
    "                score=get_roc_auc_score(temp_new_x,y,model)\n",
    "                score_lst.append(score)\n",
    "\n",
    "            new_max_score = max(score_lst) # best score\n",
    "            actual_best_score = actual_score # score passed from parameters\n",
    "\n",
    "            if(new_max_score<actual_best_score):\n",
    "                return best_x,actual_best_score # break condition, recursive function\n",
    "\n",
    "            max_score_index=[i for i, j in enumerate(score_lst) if j == new_max_score] # indx with best score \n",
    "\n",
    "            new_features=[x.columns[i] for i in max_score_index]\n",
    "            top_new_features=new_features[0]\n",
    "            temp_x=x[top_new_features]\n",
    "            best_x=pd.concat([best_x,temp_x],axis=1)\n",
    "            new_x=x.drop(top_new_features,axis=1)\n",
    "\n",
    "            return else_iteration(best_x,new_x,y,model,new_max_score)\n",
    "        \n",
    "        return best_x,actual_score\n",
    "    \n",
    "    best_x,new_x,score=first_iteration(x,y,model)\n",
    "    best_x,score=else_iteration(best_x,new_x,y,model,score)\n",
    "    \n",
    "    return best_x,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_forward_selection(x,y,c:list,gamma:list,krn='rbf',alfa=4):\n",
    "    \n",
    "    def get_best_score_index(score_lst):\n",
    "        max_score = max(score_lst) # best score\n",
    "        max_score_index=[i for i, j in enumerate(score_lst) if j == max_score] # indx with best score \n",
    "        \n",
    "        return max_score_index[0]\n",
    "    \n",
    "    def inner_iteration(x,y,c,gamma:list):      \n",
    "        print(\"c is now: {}\".format(c))\n",
    "        df_score_lst = []\n",
    "        for i in gamma:\n",
    "            SVC_clf = SVC(C=c, gamma=i,kernel=krn)\n",
    "            df,score = forward_selection(x,y,SVC_clf)\n",
    "            df_score_lst.append([df,score])\n",
    "            \n",
    "        score_lst = [y for [x,y] in df_score_lst]\n",
    "        best_index = get_best_score_index(score_lst)\n",
    "        \n",
    "        print(\"Best inner model when gamma = {}\".format(gamma[best_index]))\n",
    "        print(\"\\nFeatures\\n\")\n",
    "        for c,i in enumerate(df_score_lst[best_index][0].columns):\n",
    "            print(\"{}. {}\".format(c+1,i))\n",
    "        \n",
    "        return df_score_lst[best_index][0],df_score_lst[best_index][1],gamma[best_index]\n",
    "    \n",
    "    outer_df_score_lst = []\n",
    "    temp_best_score = 0\n",
    "    \n",
    "    tries = math.ceil((len(c)/alfa))+1 # spare tries if by some point the performance decreases\n",
    "    \n",
    "    for cnt,i in enumerate(c):\n",
    "        best_inner_df,best_inner_score,best_gamma_value = inner_iteration(x,y,i,gamma)\n",
    "        print(\"\\nSpare tries: {}\".format(tries))\n",
    "        \n",
    "        if((best_inner_score > temp_best_score) and tries > 0):\n",
    "            temp_best_score = best_inner_score\n",
    "            outer_df_score_lst.append([best_inner_df,best_inner_score,i,best_gamma_value])\n",
    "            if (cnt > 0): print(\"This iteration had an improvement\\n\")\n",
    "            elif (cnt == 0): print(\"\")             \n",
    "            tries = math.ceil((len(c)/alfa))+1             \n",
    "        else:\n",
    "            print(\"This iteration didn't have an improvement\\n\")\n",
    "            tries = tries-1\n",
    "        \n",
    "        if (tries == 0):\n",
    "            break\n",
    "                                              \n",
    "    outer_score_lst = [b for [a,b,c,d] in outer_df_score_lst]\n",
    "    best_outer_index = get_best_score_index(outer_score_lst)\n",
    "    \n",
    "    print(\"Final results\")\n",
    "    print(\"Best model when c = {} ,gamma = {} ,roc_auc = {}%\".format(outer_df_score_lst[best_outer_index][2],\n",
    "                                                                 outer_df_score_lst[best_outer_index][3],\n",
    "                                                                 outer_df_score_lst[best_outer_index][1]*100))\n",
    "    \n",
    "    return outer_df_score_lst[best_outer_index][0],outer_df_score_lst[best_outer_index][1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecesary_features=[\"m_name\"]\n",
    "x,y=get_data_and_true_prediction(mixed_df,unnecesary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lst = [10e-2,10e-1,10e0,10e1] # > 0\n",
    "gamma_lst = [10e-1,10e0,10e1] # > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c is now: 0.1\n",
      "Best inner model when gamma = 1.0\n",
      "\n",
      "Features\n",
      "\n",
      "1. n_HBD\n",
      "2. n_aliphatic_heterocycles\n",
      "3. n_O\n",
      "4. m_logp\n",
      "5. n_aromatic_carbocycles\n",
      "6. n_amide_bonds\n",
      "7. fraction_CSP3\n",
      "\n",
      "Spare tries: 2\n",
      "\n",
      "c is now: 1.0\n",
      "Best inner model when gamma = 1.0\n",
      "\n",
      "Features\n",
      "\n",
      "1. n_HBD\n",
      "2. n_aliphatic_heterocycles\n",
      "3. n_O\n",
      "4. n_atoms_stereo_centers\n",
      "5. n_amide_bonds\n",
      "6. n_briged_head_atoms\n",
      "\n",
      "Spare tries: 2\n",
      "This iteration didn't have an improvement\n",
      "\n",
      "c is now: 10.0\n",
      "Best inner model when gamma = 1.0\n",
      "\n",
      "Features\n",
      "\n",
      "1. n_HBD\n",
      "2. fraction_CSP3\n",
      "3. n_non_strict_rotable_bonds\n",
      "4. n_aromatic_carbocycles\n",
      "5. n_hetero_cycles\n",
      "6. n_O\n",
      "7. n_aliphatic_rings\n",
      "8. m_logp\n",
      "9. n_amide_bonds\n",
      "10. n_rings\n",
      "\n",
      "Spare tries: 1\n",
      "This iteration had an improvement\n",
      "\n",
      "c is now: 100.0\n",
      "Best inner model when gamma = 1.0\n",
      "\n",
      "Features\n",
      "\n",
      "1. n_HBD\n",
      "2. fraction_CSP3\n",
      "3. n_aliphatic_heterocycles\n",
      "4. n_HBA\n",
      "\n",
      "Spare tries: 2\n",
      "This iteration didn't have an improvement\n",
      "\n",
      "Final results\n",
      "Best model when c = 10.0 ,gamma = 1.0 ,roc_auc = 85.45396195679105%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00:16:18'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "df,score_normal = SVM_forward_selection(x,y,c_lst,gamma_lst)\n",
    "end = time.time()\n",
    "\n",
    "time.strftime('%H:%M:%S', time.gmtime(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
